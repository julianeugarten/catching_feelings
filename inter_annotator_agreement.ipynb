{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook was used to calculate inter-annotator agreement and confusion matrices for the *Catching Feelings* project. It is based on existing work by (author name redacted for anonymity).\n",
        "\n",
        "To run this notebook, you need as input a zipped export from Inception. For the *Catching Feelings* project, this file is available on request."
      ],
      "metadata": {
        "id": "5AxFJb72sgrn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load project and packages\n",
        "\n",
        "Fetched from: https://github.com/catalpa-cl/inceptalytics/blob/main/examples/example.ipynb\n"
      ],
      "metadata": {
        "id": "XGWMF3MEuuOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cUMRHeZu3ip-"
      },
      "outputs": [],
      "source": [
        "!pip install inceptalytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install urllib3==1.26.15 requests-toolbelt==0.10.1"
      ],
      "metadata": {
        "id": "htxLO1fNWZE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "dLgeSliUriBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from inceptalytics import Project\n",
        "import itertools\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "6skyn2863nbz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# note: upload the zip to the correct folder first\n",
        "\n",
        "f = \"add_your_file_path_here\""
      ],
      "metadata": {
        "id": "1aORlBAg6Kue"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load project\n",
        "project = Project.from_zipped_xmi(f)"
      ],
      "metadata": {
        "id": "t0955ekD5-_a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate IAA-scores\n",
        "\n",
        "! Pairwise Cohen's Kappa which disregards out-of-the-span tokens (unannotated tokens)\n",
        "\n",
        "**Results**\n",
        "Average pairwise Kappa for *Catching Feelings*:\n",
        "\n",
        "\n",
        "*   aspects: 0.8576086057095573\n",
        "*   evaluations: 0.8822340027865565\n",
        "\n"
      ],
      "metadata": {
        "id": "30lVBfNsuyN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotators = project.annotators"
      ],
      "metadata": {
        "id": "KOscq_XIFCKv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annotators"
      ],
      "metadata": {
        "id": "TIp1VIZfGCNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to ensure anonymous peer review, usernames for annotators were redacted from the code\n",
        "# if reusing, please re-insert the usernames where needed or replace with usernames of your own annotators\n",
        "\n",
        "annotators = ['name_1', \"name_2\"]"
      ],
      "metadata": {
        "id": "aTaDQ3dI-2zV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = project.source_file_names"
      ],
      "metadata": {
        "id": "bRuDuoGfFlA6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(files)"
      ],
      "metadata": {
        "id": "5ralhLIkdwUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counts for categories"
      ],
      "metadata": {
        "id": "ZO7jZv5PZo4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select category dataframe\n",
        "pos_type = \"custom.Span\"\n",
        "cat = \"aspect\"\n",
        "\n",
        "feature_path = f'{pos_type}>{cat}'\n",
        "\n",
        "pos_annos = project.select(\n",
        "    annotation=feature_path,\n",
        "    annotators = annotators,\n",
        "    source_files = files )"
      ],
      "metadata": {
        "id": "wWE8EfTmZr23"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get all annotations per source file + which annotations were made by whom\n",
        "# to preserve anonymous peer review, the annotator usernames were removed from the subsequent code\n",
        "# if reusing, please return the names to the code where needed\n",
        "\n",
        "document_annotator_matrix = pos_annos.document_annotator_matrix\n",
        "covered_texts = pos_annos.texts\n",
        "document_annotator_matrix.join(covered_texts).head()"
      ],
      "metadata": {
        "id": "2RXpWoHsusc1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annots_categories = document_annotator_matrix.join(covered_texts).dropna()"
      ],
      "metadata": {
        "id": "sJaSA0mwuwOD"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "admin_annotations_cats = annots_categories['name_1'].tolist()\n",
        "amanda_hemmons_cats = annots_categories['name_2'].tolist()"
      ],
      "metadata": {
        "id": "3j_CvA7zu-aq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annots_categories"
      ],
      "metadata": {
        "id": "-N3942BRu4oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all annotations category\n",
        "pos_annos.data_frame.annotation.value_counts()"
      ],
      "metadata": {
        "id": "PquSdWdnUiLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pos_annos.data_frame"
      ],
      "metadata": {
        "id": "K6CrnPb6U0Kl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotations for second annotator\n",
        "df[(df[\"annotator\"] == \"name_2\")][\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "cld2dd86U8iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotations for first author (separately)\n",
        "df[(df[\"annotator\"] == \"name_1\")][\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "6Wl0YddIWojc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group = df.groupby([\"source_file\"]).agg(list)"
      ],
      "metadata": {
        "id": "0O3svKu8WvjB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Files for IAA\n",
        "filtered_df = group[group['annotator'].apply(lambda x: 'name_1' in x and 'name_2' in x)]"
      ],
      "metadata": {
        "id": "QnnaYc62XQ8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# overview of all IAA texts\n",
        "filtered_df.index.unique()"
      ],
      "metadata": {
        "id": "mTReginLZA2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotation counts for the files annotated by both annotators\n",
        "filtered_df.explode(\"annotation\")[\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "2yL-WqBIYx7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Counts for sentiments (evaluation annotations)"
      ],
      "metadata": {
        "id": "HI3Ta07_Z5jn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select category dataframe\n",
        "pos_type = \"custom.Span\"\n",
        "cat = \"evaluation\"\n",
        "\n",
        "feature_path = f'{pos_type}>{cat}'\n",
        "\n",
        "pos_annos = project.select(\n",
        "    annotation=feature_path,\n",
        "    annotators = annotators,\n",
        "    source_files = files )"
      ],
      "metadata": {
        "id": "m606rBkZZ4t6"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#all annotations evaluation\n",
        "pos_annos.data_frame.annotation.value_counts()"
      ],
      "metadata": {
        "id": "ktVScbVwZ_Sg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pos_annos.data_frame"
      ],
      "metadata": {
        "id": "tYSanA-maF-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotations for Amanda (separately)\n",
        "df[(df[\"annotator\"] == \"name_2\")][\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "JDQVJO4xaNTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotations for admin (separately)\n",
        "df[(df[\"annotator\"] == \"name_1\")][\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "_dW1qohzaP_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "group = df.groupby([\"source_file\"]).agg(list)\n",
        "# Files for IAA\n",
        "filtered_df = group[group['annotator'].apply(lambda x: 'name_1' in x and 'name_2' in x)]"
      ],
      "metadata": {
        "id": "p5tnxyHUaR9M"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all unique sentences annotated by both annotators\n",
        "len(set(filtered_df.explode(\"sentence\")[\"sentence\"]))"
      ],
      "metadata": {
        "id": "7Axa9HJwd1fB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# annotation counts for the files annotated by both Amanda and admin (for evaluation)\n",
        "filtered_df.explode(\"annotation\")[\"annotation\"].value_counts()"
      ],
      "metadata": {
        "id": "OIsT7_dzaV1f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Kappa Scores"
      ],
      "metadata": {
        "id": "JzoFsqbcZ0qv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pos_type = \"custom.Span\""
      ],
      "metadata": {
        "id": "Wc10788WzLt0"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cats = [\"aspect\", \"evaluation\"]\n",
        "\n",
        "for cat in cats:\n",
        "  feature_path = f'{pos_type}>{cat}'\n",
        "\n",
        "  pos_annos = project.select(\n",
        "      annotation=feature_path,\n",
        "      annotators = annotators,\n",
        "      source_files = files )\n",
        "\n",
        "  IAA_df = pd.DataFrame(pos_annos.iaa_pairwise(measure='kappa'))\n",
        "\n",
        "  avg = IAA_df.loc[:, 'kappa'].mean()\n",
        "\n",
        "\n",
        "  print(IAA_df)\n",
        "  print(f\"Averaged pairwise Kappa score {cat} : {avg}\")"
      ],
      "metadata": {
        "id": "xtzwNOrnvLn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate IAA for sentence-level sentiment labels\n",
        "#pos_type= \"webanno.custom.Link\"\n",
        "feature = \"aspect\"\n",
        "\n",
        "\n",
        "feature_path = f'{pos_type}>{feature}'\n",
        "\n",
        "pos_annos = project.select(\n",
        "    annotation=feature_path,\n",
        "    annotators = annotators,\n",
        "    source_files = files )\n",
        "\n",
        "IAA_df = pd.DataFrame(pos_annos.iaa_pairwise(measure='kappa'))\n",
        "\n",
        "avg = IAA_df.loc[:, 'kappa'].mean()\n",
        "\n",
        "\n",
        "print(IAA_df)\n",
        "print(f\"Averaged pairwise Kappa score {cat} : {avg}\")"
      ],
      "metadata": {
        "id": "Fx1PYCRqeMLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#aantal annotaties per label for IAA FILES\n",
        "for cat in cats:\n",
        "  feature_path = f'{pos_type}>{cat}'\n",
        "\n",
        "  pos_annos = project.select(\n",
        "      annotation=feature_path,\n",
        "      annotators = annotators,\n",
        "      source_files = files )\n",
        "\n",
        "  count = pos_annos.count(grouped_by='annotation')\n",
        "\n",
        "  print(cat)\n",
        "  print(count)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "YRlFVuqKkkw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(project.source_file_names)"
      ],
      "metadata": {
        "id": "dwRtQL12cPYf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# number of annotations per label for ALL FILES\n",
        "for cat in cats:\n",
        "  feature_path = f'{pos_type}>{cat}'\n",
        "\n",
        "  pos_annos = project.select(\n",
        "      annotation=feature_path,\n",
        "      annotators = annotators,\n",
        "      source_files = project.source_file_names )\n",
        "\n",
        "  count = pos_annos.count(grouped_by='annotation')\n",
        "\n",
        "  print(cat)\n",
        "  print(count)\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "-fbXc-uB1RvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot confusion matrices for IAA tests"
      ],
      "metadata": {
        "id": "swjcHve2kcfy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_annots_confusion(feature= \"aspect\", pos_type = pos_type, to_drop = []):\n",
        "  feature_path = f'{pos_type}>{feature}'\n",
        "  pos_annos = project.select(annotation=feature_path) #project = defined outside\n",
        "\n",
        "  cm = (pos_annos.confusion_matrices(aggregate=\"total\")) #make df confusion matrix\n",
        "\n",
        "  try:\n",
        "    res = pd.DataFrame(cm).drop(columns=to_drop, index=to_drop)\n",
        "  except:\n",
        "    res = pd.DataFrame(cm)\n",
        "\n",
        "\n",
        "  df_cm = pd.DataFrame(res, index = res.keys(),\n",
        "                  columns = res.keys())\n",
        "\n",
        "  plt.figure(figsize = (10,7))\n",
        "  return sn.heatmap(df_cm, annot=True, fmt= \"d\")"
      ],
      "metadata": {
        "id": "dxa0-bPdrFjC"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_annots_confusion(feature= \"aspect\", to_drop = [\"event\"])\n",
        "\n",
        "# note: two aspects were tagged as 'event' rather than 'event and storyworld' by accident\n",
        "# to analyze the data, we drop these two"
      ],
      "metadata": {
        "id": "oIYHfEoxsgZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_annots_confusion(feature= \"evaluation\", to_drop = [])"
      ],
      "metadata": {
        "id": "0-6u6KwLsu6w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Playground"
      ],
      "metadata": {
        "id": "LmY71YZOystB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#get all annotations in a simple dataframe (......... FML)\n",
        "annos = pos_annos.data_frame\n",
        "\n",
        "annos"
      ],
      "metadata": {
        "id": "Z1gC-8EpkzPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annos.annotation.value_counts()"
      ],
      "metadata": {
        "id": "peBiTvpGP86Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_path = f'{pos_type}>{\"evaluation\"}'\n",
        "pos_annos = project.select(annotation=feature_path) #project = defined outside\n",
        "annos_sents = pos_annos.data_frame\n",
        "annos_sents[annos_sents[\"annotation\"] != \"None\"]"
      ],
      "metadata": {
        "id": "mtRn-B0-EKdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annos_sents = annos_sents[annos_sents[\"annotation\"] != \"None\"]"
      ],
      "metadata": {
        "id": "5lNoVe30Cygz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# you may want to save your annotations as a CSV\n",
        "annos_sents.to_csv(\"annotations.csv\")"
      ],
      "metadata": {
        "id": "HSy8GteBDZD3"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annos_ents"
      ],
      "metadata": {
        "id": "BoX7VyscDMpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsets_lists = [list(sub) for sub in subsets]"
      ],
      "metadata": {
        "id": "7jbFXUYBGOYQ"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annots = document_annotator_matrix.join(covered_texts).dropna()"
      ],
      "metadata": {
        "id": "SOH5KePilqLR"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "admin_annotations = annots['name_1'].tolist()\n",
        "amanda_hemmons_annotations = annots['name_2'].tolist()"
      ],
      "metadata": {
        "id": "W2JvQsh4m2LF"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annots_cats = document_annotator_matrix.join(covered_texts).dropna()"
      ],
      "metadata": {
        "id": "-tQIOUH4uAYx"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "annots_cats"
      ],
      "metadata": {
        "id": "NVJimjk2uBxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}